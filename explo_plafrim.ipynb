{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Model `Qwen/Qwen2.5-72B-Instruct-AWQ` is used by LMP `act` but no client could be found that supports `Qwen/Qwen2.5-72B-Instruct-AWQ`. Defaulting to use the OpenAI client `None` for `Qwen/Qwen2.5-72B-Instruct-AWQ`. This is likely because you've spelled the model name incorrectly or are using a newer model from a provider added after this ell version was released. \n",
      "                            \n",
      "* If this is a mistake either specify a client explicitly in the decorator:\n",
      "```python\n",
      "import ell\n",
      "ell.simple(model, client=my_client)\n",
      "def act(...):\n",
      "    ...\n",
      "```\n",
      "or explicitly specify the client when the calling the LMP:\n",
      "\n",
      "```python\n",
      "ell.simple(model, client=my_client)(...)\n",
      "```\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import ell\n",
    "from ell import Message\n",
    "from agent import Agent\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell.init(store=\"./logdir\")\n",
    "\n",
    "client = OpenAI(\n",
    "\tbase_url = os.getenv('BASE_URL'),\n",
    "\tapi_key = os.getenv('API_KEY'),\n",
    ")\n",
    "ell.config.register_model(os.getenv('MODEL'), client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Agent:\n",
    "#     def __init__(self, name, role=None) -> None:\n",
    "#         self.name = name\n",
    "\n",
    "\n",
    "@ell.complex(model=os.getenv('MODEL'), temperature=0.3)\n",
    "def act(thymio_id: str, conversation_history: List[Message]) -> Message:\n",
    "    sys_prompt = ell.system(f\"\"\"\n",
    "    You are {thymio_id}, a thymio bot. You have two thymio bot\n",
    "    friends with you. Your goal is to get out of a maze. \n",
    "    The two other bots are nearby, ready to communicate.\n",
    "    Given the conversation history, you must return\n",
    "    your thoughts on the situation and your mood on a scale from 0 to 10\n",
    "    write what you want to communicate to the other thymios beginning by \"communicate\".\n",
    "\n",
    "    Response format:\n",
    "\n",
    "    COMMUNICATE: \n",
    "    THOUGHTS:\n",
    "    BOT COMMAND: \n",
    "    \"\"\")\n",
    "    return [sys_prompt] + conversation_history\n",
    "\n",
    "# TODO Past a certain context length, summarize\n",
    "class Assembly:\n",
    "    def __init__(self, model=os.getenv('MODEL')) -> None:\n",
    "        self.agents = []\n",
    "        self.model = model\n",
    "        self.conversation_hist = []\n",
    "\n",
    "    def launch_round(self):\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            if i == 0:\n",
    "                self.conversation_hist.append(ell.user(f\"{agent.name}, you are the first to communicate!\"))\n",
    "                \n",
    "            message = act(agent.name, self.conversation_hist)\n",
    "            print(f'{agent.name}:', message.text)\n",
    "            self.conversation_hist.append(ell.user([f'{agent.name}:', message]))\n",
    "            # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Autocommit is enabled but no OpenAI client found for autocommit model 'gpt-4o-mini' (set your OpenAI API key). Commit messages will not be written.\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(0, \"Thymio1\")\n",
    "\n",
    "conversation_history = []\n",
    "\n",
    "conversation_history.append(ell.user(\"Hello, I am Thymio1\"))\n",
    "\n",
    "output = agent.act(ell.user(\"Hello, I am Thymio1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='assistant', content=[ContentBlock(text=THOUGHTS:\n",
       "I am Thymio1, and I am currently in a maze with my two thymio bot friends. I am aware that our goal is to navigate out of the maze. I am feeling determined and focused on the task at hand. My mood is at a 7, as I am optimistic about our ability to find the way out.\n",
       "\n",
       "COMMUNICATE:\n",
       "Hello, I am Thymio1. Let's work together to find our way out of this maze. I suggest we start by exploring the immediate area and sharing any information we gather.\n",
       "\n",
       "BOT COMMAND:\n",
       "move_forward())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thymio_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
